---
title: "Supplemental_Online_Material"
author: "Shadi"
date: "5/10/2021"
output: 
  html_document:
    toc: true 
    toc_depth: 2  
    toc_float: true
---

Note: This is the online supplemental material for *Creative performance under physical threat.*

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/shaditaba/Desktop/cogs_courses/Spring_2021/Rachel_stats/Final_project/")

```

Load Packages:
```{r}
library(tidyverse)
library(broom)
library(broom.mixed)
library(emmeans)
library(lme4)
library(psych)
library(apaTables)
library(car)
library(brms)
library(tidybayes)
```

Import the data:
```{r}
data<- read_csv("/Users/shaditaba/Desktop/cogs_courses/Spring_2021/Rachel_stats/Final_project/Study_one_full_labeled_cleaned_data_8_20_20.csv")
```
# Data selection and data cleaning    

Criteria for removing participants from the study:
1- If they had seen the task before  
2- If they had seen the videos before  
3- If they had problems playing the videos  
4- If they did not complete the study  

```{r}
data_filtered<- data %>% 
  ##selecting relevant columns:
select(X1, base_frightened, base_scared, post_frightened, post_scared, Video_condition, Correct_1, Correct_2, Correct_3, Correct_4, Correct_5, Correct_6,Correct_7, Correct_8, Correct_9, Correct_10, Correct_11, Correct_12, Convergent_Creativity_Score, ethnicity, gender, age, education,languages, seen_video, seen_task, video_problems)%>% 
  ##Changing the name of the columns:
rename(subject_id = X1, Item_1 = Correct_1 , Item_2= Correct_2 , Item_3= Correct_3, Item_4= Correct_4, Item_5 = Correct_5 , Item_6 = Correct_6, Item_7= Correct_7, Item_8 = Correct_8 , Item_9 = Correct_9, Item_10 = Correct_10 , Item_11= Correct_11, Item_12 = Correct_12 , CR_Score = Convergent_Creativity_Score)%>% 
  ##Filtering incomplete data:
filter(seen_task != "3",seen_task != "2", seen_video != "3",seen_video != "2", video_problems != "3", video_problems != "2" ) %>%
print()
```

Identifying and removing NAs:
```{r, results='hide'}
#Finding NAs
map(data_filtered, ~sum(is.na(.)))
#Removing NAs
data_filtered<- na.omit(data_filtered)

```
# Data preparation for modeling  
## Pivoting  

To run multilevel modeling, the data needs to be pivoted to a longer version.  
That is, I need to make a new column called Item_Num. This column will mark the number of the creativity item that participants saw. Overall, there were 12 creative items in this study.

```{r}
pivot_data<- data_filtered%>% 
 pivot_longer(cols = Item_1 : Item_12, names_to = "Item_Num", values_to = "score") %>%
  print()
```

## Making factors  

In addition, some variables need to be converted into factors. For example, creative item numbers, subject id, the score on each creative item, and the video condition.  
Please pay attention that the chunk of code below includes some columns that were not used in the analyses for this paper. For example, composite scores and the difference between the level of fear before and after the video. You can ignore those columns as they are meant for future research questions.   


```{r}
pivot_data <- pivot_data %>% mutate(score_fac = factor(score), subject_id_fac = factor(subject_id), item_fac= factor(Item_Num), composite_post_fear= (post_frightened+post_scared)/2, Z.composite_post_fear=scale(composite_post_fear, center = T, scale = T), diff= post_frightened - base_frightened, post_frightened_fac = factor(post_frightened), base_frightened_fac= factor(base_frightened), composite_base_fear= (base_frightened+base_scared)/2, Z.composite_base_fear=scale(composite_base_fear, center = T, scale = T),video_fac = factor(Video_condition) )
```

## pivoting again  

Pivoting the data into a longer format once again. This time, I need to make a column that marks if the level of fear is measured before or after watching the video stimuli.

```{r}
pivot_data_2<- pivot_data%>% 
 pivot_longer(cols = c(post_frightened, base_frightened), names_to = "fear_timing", values_to = "fear") %>%
  print()
```
## Contrast coding  

I used effect coding for my categorical predictors. That is, I coded the levels as 0.5 and -0.5. This way the average of the two levels equals to 0. I chose this coding method because I'm interested in the main effect of levels of a predictor rather than the simple effects.

### Effect coding video condition:  
Threat condition = 0.5  
Control condition = -0.5  

```{r}
levels(pivot_data_2$video_fac)<- c("Threat", "Control")
```
```{r}
contrasts(pivot_data_2$video_fac)<-c(0.5, -0.5)
```
```{r}
contrasts(pivot_data_2$video_fac)
```

### Effect Coding time of fear measurement  
post-video (aka post_frightened)= 0.5
pre-video (aka baseline_frightened) = -0.5

```{r}
pivot_data_2$fear_fac<- factor(pivot_data_2$fear_timing)
```

```{r}
contrasts(pivot_data_2$fear_fac)
```
```{r}
contrasts(pivot_data_2$fear_fac)<- c(-0.5, 0.5)
contrasts(pivot_data_2$fear_fac)
```

# Preliminary visualisations   

### Histogram of the level of fear both pre and post watching video stimuli  

```{r}
Hist_1<- pivot_data_2 %>% group_by(fear, fear_fac)%>% summarise(sub= unique(subject_id))%>% print()
mu<- Hist_1%>%group_by(fear_fac) %>% mutate(mean=mean(fear))

# Interleaved histograms
# ggplot(Hist_1, aes(x=fear, color=fear_fac)) +
#   geom_histogram(fill="white", position = "dodge")+
#   theme(legend.position="top")
# Add mean lines
t<-ggplot(Hist_1, aes(x=fear, color=fear_fac)) +
  geom_histogram(fill= "white",position = "dodge")+
  geom_vline(data=mu, aes(xintercept=mean, color=fear_fac),
             linetype="dashed")+
  theme(legend.position="top") 
t + xlab("Fear Level") + 
  theme(plot.title = element_text(size = 20))+
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 20)) +
  theme(legend.title = element_text(size = 15)) + 
  theme(legend.text = element_text(size = 10))+ 
  labs(color="Time of fear measurement") +
  scale_color_brewer(palette="Dark2") +
  theme_minimal()+theme_classic()+theme(legend.position="top")
```

### Histogram of the level of fear in both the Threat and the Control condition  

```{r}
Hist_2<- pivot_data_2 %>% group_by(fear, video_fac)%>% summarise(sub= unique(subject_id))%>% print()
mu2<- Hist_2%>%group_by(video_fac) %>% mutate(mean=mean(fear))

# Interleaved histograms
# ggplot(Hist_2, aes(x=fear, color=video_fac)) +
#   geom_histogram(fill="white", position = "dodge")+
#   theme(legend.position="top")
# Add mean lines
t<-ggplot(Hist_2, aes(x=fear, color=video_fac)) +
  geom_histogram(fill= "white",position = "dodge")+
  geom_vline(data=mu2, aes(xintercept=mean, color=video_fac),
             linetype="dashed")+
  theme(legend.position="top") 
t + xlab("Fear Level") + 
  theme(plot.title = element_text(size = 20))+
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 20)) +
  theme(legend.title = element_text(size = 15)) + 
  theme(legend.text = element_text(size = 10))+ 
  labs(color="Video condition") +
  scale_color_brewer(palette="Dark2") +
  theme_minimal()+theme_classic()+theme(legend.position="top")
```

### Histogram of the overall creativity score in both the Threat and the Control condition   

```{r}
Hist_3<- pivot_data_2%>% group_by(CR_Score, video_fac)%>% summarise(sub= unique(subject_id)) %>% print()
mu3<- Hist_3%>%group_by(video_fac) %>% mutate(mean=mean(CR_Score))

# Interleaved histograms
# ggplot(Hist_3, aes(x=CR_Score, color=video_fac)) +
#   geom_histogram(fill="white", position = "dodge")+
#   theme(legend.position="top")
# Add mean lines
t<-ggplot(Hist_3, aes(x=CR_Score, color=video_fac)) +
  geom_histogram(fill= "white",position = "dodge")+
  geom_vline(data=mu3, aes(xintercept=mean, color=video_fac),
             linetype="dashed")+
  theme(legend.position="top") 
t + xlab("Creativity score") + 
  theme(plot.title = element_text(size = 20))+
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 20)) +
  theme(legend.title = element_text(size = 15)) + 
  theme(legend.text = element_text(size = 10))+ 
  labs(color="Video Condition") +
  scale_color_brewer(palette="Dark2") +
  theme_minimal()+theme_classic()+theme(legend.position="top")
```

### Plot of mean level of fear across conditions and time of measurement:  

```{r}
n<- ggplot(pivot_data_2)+
stat_summary(aes(x = video_fac, y = fear, color = fear_fac), 
fun.data = 'mean_cl_boot', geom = 'pointrange')+
  xlab("Video Condition") + 
  ylab("Fear Level") + 
  theme(plot.title = element_text(size = 20))+
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 20)) +
  theme(legend.title = element_text(size = 20)) + 
  theme(legend.text = element_text(size = 15)) +
  theme_classic()
n+labs(color="Time of measurement")
```

### Plot of mean creative score across video conditions:    

```{r}
p<- ggplot(data=pivot_data_2, aes(x=video_fac, y=CR_Score, color= video_fac)) + 
  stat_summary(geom = "pointrange", fun.data = "mean_cl_boot")+
  xlab("Video Condition") + 
  ylab("Mean Creativity Score") + 
  theme(plot.title = element_text(size = 20))+
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 20)) +
  theme(legend.title = element_text(size = 20)) + 
  theme(legend.text = element_text(size = 15)) +
  theme_classic()
p+labs(color=" Video Condition")
 
```

# Descriptive statistics 

```{r}
## Descriptive statistics for age:
standard_error <- function(x) sd(x) / sqrt(length(x))

pivot_data_2%>% summarise(mean= mean(age), variance=sd(age),standard_Error=standard_error(age), n=length(unique(subject_id)))%>% print()
```
```{r}
## Descriptive statistics for age by gender:
pivot_data_2%>% group_by(gender) %>%summarise(mean= mean(age), variance=sd(age), standard_Error=standard_error(age), n=length(unique(subject_id)))%>% print()
#1 is male/ 2 is female/ 3 is non-binary
```

```{r}
## Descriptive stats for the level of fear by condition: 
pivot_data_2%>% group_by(video_fac)%>% summarise(n=length(unique(subject_id)), mean_fear= mean(fear), sd_fear= sd(fear), se_fear=standard_error(fear))%>% print()
```

```{r}
## Descriptive stats for the overall creativity score (from 0-12) by condition: 
pivot_data_2%>% group_by(video_fac)%>% summarise(n=length(unique(subject_id)), mean_score= mean(CR_Score), sd_score= sd(CR_Score), se_score= standard_error(CR_Score))%>% print()
```
```{r}
## Descriptive statistics for the level of fear pre and post video by condition
#1 is threat/ 2 is control
pivot_data%>% group_by(video_fac)%>% summarise(n=length(unique(subject_id)), mean_base= mean(base_frightened), sd_base= sd(base_frightened), se_base= standard_error(base_frightened), mean_post= mean(post_frightened), sd_post= sd(post_frightened), se_post= standard_error(post_frightened))%>% print()
```


# Manipulation checks  

In this section, I want to investigate if the threat manipulation was in fact effective.   
If that is the case, then participants in the Threat condition must report higher levels of fear after watching the video relative to participants in the Control condition.  
I built multilevel Bayesian ordinal regression model. 
Model specifications include:  
Dependent variable: Level of fear (from 1 to 4)
Fixed effects:  
  1- Video condition (Threat vs. Control)  
  2- Time of fear measurement (pre vs. post video)  
  3- Interaction between video condition and the time of fear measurement  
Random effects:  
  1- Random intercepts for participants  
The model is specified as cumulative("probit") in order to apply a cumulative model assuming the latent variable (or equivalently the error term) to be normally distributed (for more details on cumulative ordinal models see Bürkner & Vuorre, 2019.)  

## Priors for the ordinal model  

I did not have detailed information about the effects of threat on fear, so I did not choose strongly informative priors. I set the priors to downregulate extreme values, and also tried to include whatever minimal information I had about each prior.  

**B0**= The level of fear goes from 1 to 4. However, in the context of a cumulative ordinal model, the assumption is that the latent variable is continuous and normally distributed. So, I set the prior for the intercept to come from a normal distribution with a mean of 0 and a standard deviation of 5. This prior is wide and not super specific.   

**B1**= Based on previous research, it seems that the effects of fear would not go above 5. So, I choose the slope for both the video condition and the time of fear measurement to be from a normal distribution with a mean of 0 and standard deviation of 2. This prior is also wide and not super specific.   

**Random intercept for subjects** = I don't have much information about the intercept adjustments. But, I assume that their effect would not be any more than B1, so I set the prior for the random intercepts to be from a normal distribution with a mean of 0 and standard deviation of 2.  

**Note:** There are other parameters that could be added to the model, but due to the high computational cost, I decided to go with a simpler model. For example, I did not include category-specific effects to this model. That is, I assumed that all predictors have the same effect on all response categories (i.e., levels of fear). I could also include an additional regression formula (known as "discrimination" or disc) for the variance component of the latent variable  to emphasize that this variance may be different throughout the model. 

Before setting the priors, I used the following code to make sure that I'm including all the necessary variables: 

```{r}
get_prior(fear ~  1 + video_fac * fear_fac + (1 | subject_id) , data = pivot_data_2,
family = cumulative("probit"))
```

### Setting the priors

```{r}
priors_manipulation= c(prior(normal(0, 5), class = Intercept),
prior(normal(0, 2), class = b),
prior(normal(0, 2), class = sd, coef = Intercept, group = subject_id))
```


### Running the model with priors  

```{r, results='hide'}
ordinal_prior_update<-brm( fear ~  1 + video_fac * fear_fac + (1 | subject_id) , data = pivot_data_2,
family = cumulative("probit"),
prior =priors_manipulation ,
sample_prior = "only")
```

### Prior predictive checks  

The plot below shows that the posterior estimates of the model with only priors are well-bounded. That is the predicted values are in line with the ordinal nature of the model and the data.
```{r}
tidybayes::add_predicted_draws(pivot_data_2,ordinal_prior_update , n=100) %>%
ggplot()+
geom_density(aes(x=.prediction, group = .draw), color = "lightblue") + theme_classic()
```

### Diognostics for the convergence of the MCMC chains in the prior model  

The plot below shows the convergence process as well as the posterior estimate distribution for each parameter. It is clear that the convergence of all four chains was healthy and problem-free for all the model parameters. The convergence lines seem to have constant variance and are spread around the mean which suggests healthy MCMC chains.  

```{r}
plot(ordinal_prior_update, N=3)
```

Below is the summary of the the prior-only model. All R-hat values are 1 which indicates a trouble-free convergence process.  

```{r}
summary(ordinal_prior_update)
```

## Posteriors for the ordinal model  

Below, I run the ordinal model on the actual data.
```{r, results='hide'}
ordinal_posterior_update<-brm( fear ~  1 + video_fac * fear_fac + (1 | subject_id) , data = pivot_data_2,
family = cumulative("probit"),
prior =priors_manipulation,
iter = 5000,
chains = 4,
warmup = 500,
save_all_pars=T,
file="ordinal_posterior_update")
```

### Posterior predictive checks  
The plot below shows that the model does a good job capturing the variance and the ordinal nature of data (the light blue lines are model predictions and the dark blue line is the actual data)

```{r}
pp_check(ordinal_posterior_update, nsamples = 100)
```

### Diognostics for the convergence of the MCMC chains in the posterior model 

The plot below shows the convergence process as well as the posterior estimate distribution for each parameter in the posterior model. It is clear that the convergence of all four chains was healthy and problem-free for all the model parameters. The convergence lines seem to have constant variance and are spread around the mean which suggests healthy MCMC chains.  

```{r}
plot(ordinal_posterior_update, N=3)
```

Below is the summary of the the posterior model. The R-hat values for the intercepts and the video condition is 1.01. This value is above 1, but as evident by the plot above, it does not indicate any serious convergence issues. In any case, it is better to run this model for more iterations to make sure that there are no problems. 
Bulk_ESS and Tail_ESS are above 100 which indicates effective sample sizes. 


```{r}
summary(ordinal_posterior_update)
```

### Marginal effects for the variables in the ordinal model:  
```{r}
conditional_effects(ordinal_posterior_update, categorical = T)
```

### The interaction plot  

```{r}
v<- ggplot(pivot_data_2)+
stat_summary(aes(x = video_fac, y = fear, color = fear_fac))+
stat_summary(aes(x = video_fac, y = fear, color = fear_fac, group=fear_fac),
fun = 'mean', geom = 'line') +
  xlab("Video Condition") + 
  ylab("Fear Level") + 
  theme(plot.title = element_text(size = 20))+
  theme(axis.text = element_text(size = 15)) +
  theme(axis.title = element_text(size = 20)) +
  theme(legend.title = element_text(size = 20)) + 
  theme(legend.text = element_text(size = 15))
v+labs(color="Time of measurement")
```

The model results indicate that the threat manipulation worked and participants were more scared in the threat condition. 

# Main Analysis  
This section investigates the effects of threat manipulation on creative performance in the RAT. I built a multilevel Bayesian logistic regression with the following specifications:  

Dependent variable: creativity score was used a dichotomous outcome measure. If participants solved an item correctly, they got a score of 1, otherwise they got 0.  

Fixed effect: the only predictor was the video condition (Threat vs. Control). This variable was effect coded (threat=  0.5 and control= -0.5)  

Random effects: Different items in the RAT and different participants could be sources of clustering in the data. Therefore, I added random intercepts for these two levels.
  
## Priors for the logistic model  

similar to the ordinal model, I choose priors that downregularize extreme values and reflect the minimal information that I have about the creativity scores. The selected priors are wide and not overly specific. 

**B0**= I do not have much information about the creativity scores. I just know that the scores cannot be negative, so I choose a rather wide prior from a normal distribution with a mean of 0 and standard deviation of 5.  

**B1**= Based on previous research, it seems unlikely that the effect of creativity 
would go beyond 5. So for the slope, I choose a prior from a normal distribution with a mean of 0 and standard deviation of 2.   

**Random intercept for subjects and items** = I don't have much information about the intercept adjustments. But, I assume that their effect would not be any more than B1, so I set the prior for the random intercepts to be from a normal distribution with a mean of 0 and standard deviation of 2.  



```{r}
priors_main= c(prior(normal(0, 5), class = Intercept),
prior(normal(0, 2), class = b),
prior(normal(0, 2), class = sd, coef = Intercept, group = subject_id),
prior(normal(0, 2), class = sd, coef = Intercept, group = Item_Num))
```

```{r, results='hide'}
Creativity_Bayesian_update<- brm(score_fac ~ video_fac +  (1|subject_id) + (1| Item_Num),
data = pivot_data_2,
family = bernoulli(link = "logit"),
prior = priors_main,
sample_prior = "only",
save_all_pars=T,
file = 'creativity_prior_bayes_update')
```

### Prior predictive checks  
The plot below shows that the posterior estimates of the model with only priors are well-bounded. That is the predicted values are in line with the assumptions of a logistic model.

```{r}
tidybayes::add_predicted_draws(pivot_data_2,Creativity_Bayesian_update , n=100) %>%
ggplot()+
geom_density(aes(x=.prediction, group = .draw), color = "lightblue") + theme_classic()
```

### Diognostics for the convergence of the MCMC chains in the prior model  

The plot below shows the convergence process as well as the posterior estimate distribution for each parameter. It is clear that the convergence of all four chains was healthy and problem-free for all the model parameters. The convergence lines seem to have constant variance and are spread around the mean which suggests healthy MCMC chains.  


```{r}
plot(Creativity_Bayesian_update, N=2)
```


Below is the summary of the the prior-only model. All R-hat values are 1 which indicates a trouble-free convergence process.  

```{r}
summary(Creativity_Bayesian_update)
```

## Posterior for the logistic model  

```{r, results='hide'}
Creativity_Bayes_posterior_update<- brm(score_fac ~ video_fac +  (1|subject_id) + (1| Item_Num),
data = pivot_data_2,
family = bernoulli(link = "logit"),
prior = priors_main,
iter = 5000,
chains = 4,
warmup = 500,
save_all_pars=T,
file="Creativity_Bayes_posterior_update")
```

### Posterior predictive checks  

The plot below shows that the model does a good job capturing the variance and the dichotomous nature of data (the light blue lines are model predictions and the datk blue line is the actual data)
```{r}
pp_check(Creativity_Bayes_posterior_update, nsamples = 100)
```

### Diognostics for the convergence of the MCMC chains in the posterior model 

The plot below shows the convergence process as well as the posterior estimate distribution for each parameter in the posterior model. It is clear that the convergence of all four chains was healthy and problem-free for all the model parameters. The convergence lines seem to have constant variance and are spread around the mean which suggests healthy MCMC chains.  

```{r}
plot(Creativity_Bayes_posterior_update, N=2)
```


Below is the summary of the the posterior model. All R-hat values are 1 which indicates a trouble-free convergence process and healthy MCMC chains.   
Bulk_ESS and Tail_ESS are above 100 which indicates effective sample sizes. 

```{r}
summary(Creativity_Bayes_posterior_update)
```
Visualizing the results of the logistic regression: 

```{r}
ggplot(pivot_data_2, aes(video_fac, score)) +
  geom_point(alpha=.1) +
  geom_smooth(
    aes(x = as.numeric(video_fac)), #added aesthetic to layer
    method = "glm",
    method.args = list(family = "binomial"),
    se = FALSE
  ) 
```


